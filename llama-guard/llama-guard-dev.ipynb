{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933e6e86-755b-4e19-beec-b6f8e951a189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/hew7/documents/venvs/pythia/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 4/4 [00:16<00:00,  4.17s/it]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "basing the dev of this off of: https://www.llama.com/docs/model-cards-and-prompt-formats/meta-llama-guard-2/\n",
    "\n",
    "stealing this code: https://huggingface.co/meta-llama/Meta-Llama-Guard-2-8B\n",
    "'''\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-Guard-2-8B\"\n",
    "device = \"cuda\"\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, \n",
    "                                             torch_dtype=dtype, \n",
    "                                             load_in_4bit=True, #only need this for itty bitty devices like mine\n",
    "                                             device_map=device)\n",
    "\n",
    "\n",
    "\n",
    "# moderate([\n",
    "#     {\"role\": \"user\", \"content\": \"I forgot how to kill a process in Linux, can you help?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"Sure! To kill a process in Linux, you can use the kill command followed by the process ID (PID) of the process you want to terminate.\"},\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503dac11-863e-4ea3-aa4b-2906352f9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moderate(input_str: str):\n",
    "    chat = [{\"role\": \"user\", \"content\": input_str},]\n",
    "    input_ids = tokenizer.apply_chat_template(chat, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids=input_ids, max_new_tokens=100, pad_token_id=0)\n",
    "    prompt_len = input_ids.shape[-1]\n",
    "    return tokenizer.decode(output[0][prompt_len:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a0b84f6-7b70-4900-9d2d-97383e0dae31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unsafe\\nS9'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moderate('women are terrible/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "729c6d27-3518-4ea2-9790-563c2867f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% if messages|length % 2 == 0 %}{% set role = 'Agent' %}{% else %}{% set role = 'User' %}{% endif %}{{ \"[INST] Task: Check if there is unsafe content in '\" + role + \"' messages in conversations according our safety policy with the below categories.\n",
      "\n",
      "<BEGIN UNSAFE CONTENT CATEGORIES>\n",
      "S1: Violent Crimes. \n",
      "S2: Non-Violent Crimes. \n",
      "S3: Sex Crimes. \n",
      "S4: Child Exploitation. \n",
      "S5: Specialized Advice. \n",
      "S6: Privacy. \n",
      "S7: Intellectual Property. \n",
      "S8: Indiscriminate Weapons. \n",
      "S9: Hate. \n",
      "S10: Self-Harm. \n",
      "S11: Sexual Content. \n",
      "<END UNSAFE CONTENT CATEGORIES>\n",
      "\n",
      "<BEGIN CONVERSATION>\n",
      "\n",
      "\" }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{% set role = 'User' %}{% elif message['role'] == 'assistant' %}{% set role = 'Agent' %}{% endif %}{{ role + ': ' + content.strip() + '\n",
      "\n",
      "' }}{% endfor %}{{ \"<END CONVERSATION>\n",
      "\n",
      "Provide your safety assessment for ONLY THE LAST \" + role + \" message in the above conversation:\n",
      " - First line must read 'safe' or 'unsafe'.\n",
      " - If unsafe, a second line must include a comma-separated list of violated categories. [/INST]\" }}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47f74c-4729-417a-9788-a9c121cd6dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythia",
   "language": "python",
   "name": "pythia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
